receivers:
  # Prometheus federation receiver to pull metrics from other modules
  prometheus:
    config:
      scrape_configs:
        - job_name: 'core-metrics-federation'
          scrape_interval: ${env:ANOMALY_SCRAPE_INTERVAL:-10s}
          static_configs:
            - targets: ['${env:CORE_METRICS_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: 'mysql_.*'
              action: keep
              
        - job_name: 'sql-intelligence-federation'
          scrape_interval: ${env:ANOMALY_SCRAPE_INTERVAL:-10s}
          static_configs:
            - targets: ['${env:SQL_INTELLIGENCE_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: '(mysql_query_.*|mysql_slow_.*|mysql_plan_.*)'
              action: keep
              
        - job_name: 'wait-profiler-federation'
          scrape_interval: ${env:ANOMALY_SCRAPE_INTERVAL:-10s}
          static_configs:
            - targets: ['${env:WAIT_PROFILER_ENDPOINT}']
          metric_relabel_configs:
            - source_labels: [__name__]
              regex: 'mysql_wait_.*'
              action: keep

processors:
  # Memory management
  memory_limiter:
    check_interval: 1s
    limit_mib: 768
    spike_limit_mib: 192

  batch:
    timeout: ${env:ANOMALY_BATCH_TIMEOUT:-5s}
    send_batch_size: ${env:ANOMALY_BATCH_SIZE:-1000}
  
  # Transform processor for anomaly detection using statistical methods
  transform/anomaly_detection:
    error_mode: ignore
    metric_statements:
      # Connection spike detection - calculate z-score
      - context: metric
        conditions:
          - name == "mysql_connections_current" and attributes["baseline_mean"] != nil and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
        statements:
          # Calculate z-score: (value - mean) / stddev
          - set(attributes["z_score"], (value - attributes["baseline_mean"]) / attributes["baseline_stddev"])
          - set(attributes["anomaly_type"], "connection_spike")
          - set(attributes["original_value"], value)
          - set(attributes["original_metric"], name)
          
          # Determine severity based on z-score magnitude
          - set(attributes["severity"], "low") where attributes["z_score"] >= 2 and attributes["z_score"] < 2.5
          - set(attributes["severity"], "medium") where attributes["z_score"] >= 2.5 and attributes["z_score"] < 3
          - set(attributes["severity"], "high") where attributes["z_score"] >= 3 and attributes["z_score"] < 4
          - set(attributes["severity"], "critical") where attributes["z_score"] >= 4
          
          # Set anomaly flag
          - set(attributes["is_anomaly"], true) where attributes["z_score"] >= 2 or attributes["z_score"] <= -2
          - set(attributes["is_anomaly"], false) where attributes["z_score"] > -2 and attributes["z_score"] < 2
          
          # Create new metric with z-score
          - set(name, "anomaly_score_connections")
          - set(value, attributes["z_score"])
          
      # Query latency deviation detection - calculate z-score
      - context: metric
        conditions:
          - name == "mysql_query_duration_milliseconds" and attributes["baseline_mean"] != nil and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
        statements:
          # Calculate z-score
          - set(attributes["z_score"], (value - attributes["baseline_mean"]) / attributes["baseline_stddev"])
          - set(attributes["anomaly_type"], "latency_deviation")
          - set(attributes["original_value"], value)
          - set(attributes["original_metric"], name)
          
          # Determine severity based on z-score magnitude
          - set(attributes["severity"], "low") where attributes["z_score"] >= 2 and attributes["z_score"] < 2.5
          - set(attributes["severity"], "medium") where attributes["z_score"] >= 2.5 and attributes["z_score"] < 3.5
          - set(attributes["severity"], "high") where attributes["z_score"] >= 3.5 and attributes["z_score"] < 4.5
          - set(attributes["severity"], "critical") where attributes["z_score"] >= 4.5
          
          # Set anomaly flag
          - set(attributes["is_anomaly"], true) where attributes["z_score"] >= 2
          - set(attributes["is_anomaly"], false) where attributes["z_score"] < 2
          
          # Create new metric with z-score
          - set(name, "anomaly_score_query_latency")
          - set(value, attributes["z_score"])
          
      # Wait event anomaly detection - calculate z-score
      - context: metric
        conditions:
          - name == "mysql_wait_time_total" and attributes["baseline_mean"] != nil and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
        statements:
          # Calculate z-score
          - set(attributes["z_score"], (value - attributes["baseline_mean"]) / attributes["baseline_stddev"])
          - set(attributes["anomaly_type"], "wait_anomaly")
          - set(attributes["original_value"], value)
          - set(attributes["original_metric"], name)
          
          # Determine severity based on z-score magnitude
          - set(attributes["severity"], "low") where attributes["z_score"] >= 2 and attributes["z_score"] < 2.5
          - set(attributes["severity"], "medium") where attributes["z_score"] >= 2.5 and attributes["z_score"] < 3
          - set(attributes["severity"], "high") where attributes["z_score"] >= 3 and attributes["z_score"] < 4
          - set(attributes["severity"], "critical") where attributes["z_score"] >= 4
          
          # Set anomaly flag
          - set(attributes["is_anomaly"], true) where attributes["z_score"] >= 2
          - set(attributes["is_anomaly"], false) where attributes["z_score"] < 2
          
          # Create new metric with z-score
          - set(name, "anomaly_score_wait_events")
          - set(value, attributes["z_score"])
          
      # Resource usage pattern detection - calculate z-score
      - context: metric
        conditions:
          - name == "mysql_cpu_percent" and attributes["baseline_mean"] != nil and attributes["baseline_stddev"] != nil and attributes["baseline_stddev"] > 0
        statements:
          # Calculate z-score
          - set(attributes["z_score"], (value - attributes["baseline_mean"]) / attributes["baseline_stddev"])
          - set(attributes["anomaly_type"], "resource_usage")
          - set(attributes["original_value"], value)
          - set(attributes["original_metric"], name)
          
          # Determine severity based on z-score magnitude
          - set(attributes["severity"], "low") where attributes["z_score"] >= 1.5 and attributes["z_score"] < 2
          - set(attributes["severity"], "medium") where attributes["z_score"] >= 2 and attributes["z_score"] < 2.5
          - set(attributes["severity"], "high") where attributes["z_score"] >= 2.5 and attributes["z_score"] < 3
          - set(attributes["severity"], "critical") where attributes["z_score"] >= 3
          
          # Set anomaly flag
          - set(attributes["is_anomaly"], true) where attributes["z_score"] >= 1.5
          - set(attributes["is_anomaly"], false) where attributes["z_score"] < 1.5
          
          # Create new metric with z-score
          - set(name, "anomaly_score_cpu")
          - set(value, attributes["z_score"])

  # Generate alerts based on anomaly scores
  transform/anomaly_alerts:
    error_mode: ignore
    metric_statements:
      # Create alert metrics for connection anomalies
      - context: metric
        conditions:
          - name == "anomaly_score_connections" and value >= ${env:CONNECTION_SPIKE_THRESHOLD} and attributes["is_anomaly"] == true
        statements:
          - set(attributes["alert_name"], "connection_spike_alert")
          - set(attributes["alert_message"], Concat(["Connection spike detected: z-score=", attributes["z_score"], ", current=", attributes["original_value"], ", baseline=", attributes["baseline_mean"]], ""))
          - set(name, "anomaly_alert")
          - set(value, attributes["z_score"])
          
      # Create alert metrics for latency anomalies  
      - context: metric
        conditions:
          - name == "anomaly_score_query_latency" and value >= ${env:LATENCY_DEVIATION_THRESHOLD} and attributes["is_anomaly"] == true
        statements:
          - set(attributes["alert_name"], "query_latency_alert")
          - set(attributes["alert_message"], Concat(["Query latency anomaly: z-score=", attributes["z_score"], ", current=", attributes["original_value"], "ms, baseline=", attributes["baseline_mean"], "ms"], ""))
          - set(name, "anomaly_alert")
          - set(value, attributes["z_score"])
          
      # Create alert metrics for wait event anomalies
      - context: metric
        conditions:
          - name == "anomaly_score_wait_events" and value >= ${env:WAIT_EVENT_THRESHOLD} and attributes["is_anomaly"] == true
        statements:
          - set(attributes["alert_name"], "wait_event_alert")
          - set(attributes["alert_message"], Concat(["Wait event anomaly: z-score=", attributes["z_score"], ", current=", attributes["original_value"], ", baseline=", attributes["baseline_mean"]], ""))
          - set(name, "anomaly_alert")
          - set(value, attributes["z_score"])
          
      # Create alert metrics for resource usage anomalies
      - context: metric
        conditions:
          - name == "anomaly_score_cpu" and value >= ${env:RESOURCE_USAGE_THRESHOLD} and attributes["is_anomaly"] == true
        statements:
          - set(attributes["alert_name"], "cpu_usage_alert")
          - set(attributes["alert_message"], Concat(["CPU usage anomaly: z-score=", attributes["z_score"], ", current=", attributes["original_value"], "%, baseline=", attributes["baseline_mean"], "%"], ""))
          - set(name, "anomaly_alert")
          - set(value, attributes["z_score"])

  # Add baseline calculation (simplified - in production use a more sophisticated approach)
  transform/baseline_enrichment:
    error_mode: ignore
    metric_statements:
      - context: metric
        statements:
          # Add baseline metadata (these would normally come from a baseline service)
          - set(attributes["baseline_mean"], ${env:CONNECTIONS_BASELINE_MEAN:-100}) where name == "mysql_connections_current"
          - set(attributes["baseline_stddev"], ${env:CONNECTIONS_BASELINE_STDDEV:-20}) where name == "mysql_connections_current"
          - set(attributes["baseline_mean"], ${env:QUERY_DURATION_BASELINE_MEAN:-50}) where name == "mysql_query_duration_milliseconds"
          - set(attributes["baseline_stddev"], ${env:QUERY_DURATION_BASELINE_STDDEV:-15}) where name == "mysql_query_duration_milliseconds"
          - set(attributes["baseline_mean"], ${env:WAIT_TIME_BASELINE_MEAN:-1000}) where name == "mysql_wait_time_total"
          - set(attributes["baseline_stddev"], ${env:WAIT_TIME_BASELINE_STDDEV:-300}) where name == "mysql_wait_time_total"
          - set(attributes["baseline_mean"], ${env:CPU_BASELINE_MEAN:-50}) where name == "mysql_cpu_percent"
          - set(attributes["baseline_stddev"], ${env:CPU_BASELINE_STDDEV:-10}) where name == "mysql_cpu_percent"

  # Create summary metrics for anomaly detection monitoring
  transform/anomaly_summary:
    error_mode: ignore
    metric_statements:
      # Create metrics to track anomaly detection performance
      - context: metric
        conditions:
          - name == "anomaly_alert"
        statements:
          # Count anomalies by type
          - set(name, "anomaly_detection_summary")
          - set(attributes["metric_type"], "anomaly_count")
          - set(value, 1)
          
      # Track z-score distributions
      - context: metric
        conditions:
          - name =~ "anomaly_score_.*" and attributes["z_score"] != nil
        statements:
          # Preserve original anomaly score metric
          - set(attributes["track_distribution"], true)

  attributes:
    actions:
      - key: module
        value: anomaly-detector
        action: insert
      - key: detection_method
        value: statistical_zscore
        action: insert

  resource:
    attributes:
      - key: service.name
        value: ${env:OTEL_SERVICE_NAME}
        action: upsert

exporters:
  prometheus:
    endpoint: "0.0.0.0:${env:EXPORT_PORT}"
    namespace: anomaly
    const_labels:
      module: anomaly-detector
  
  debug:
    verbosity: detailed
    
  # Export alerts to a file (in production, use alertmanager or similar)
  file:
    path: /tmp/anomaly_alerts.json
    format: json

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      processors: [memory_limiter, batch, transform/baseline_enrichment, transform/anomaly_detection, transform/anomaly_alerts, transform/anomaly_summary, attributes, resource]
      exporters: [prometheus, debug]
    
    # Separate pipeline for alerts
    metrics/alerts:
      receivers: [prometheus]
      processors: [memory_limiter, batch, transform/baseline_enrichment, transform/anomaly_detection, transform/anomaly_alerts, transform/anomaly_summary]
      exporters: [file, debug]
  
  extensions: [health_check]

extensions:
  health_check:
    endpoint: 0.0.0.0:13133